\chapter{Background and Literature Review}\label{c:background}

This chapter first provides a review of relevant source detection literature, which discusses the most well-used extended source detection techniques as well as recent efforts to apply Bayesian methods to the problem. The remainder of the chapter then explains necessary background concepts from statistics and machine learning.

\section{Literature Review}
Algorithms for the extraction of sources from astronomical images have been in development for at least three decades \cite{jarvis1981focas}. The most prominent of these is SExtractor\cite{bertin1996sextractor} (Source Extractor), which is proficient at finding high-intensity sources. It begins by estimating a Gaussian model of the background, and then finds pixels above some threshold (often $5\sigma$) of the background mean. These pixels are likely sources, and photometry is then performed to fit an ellipse to those pixels. SExtractor scales linearly with the number of pixels and is the de-facto standard for source detection. Other popular source detection algorithms, such as Duchamp \cite{whiting2012duchamp} (which finds sources in three-dimensional spectral line cubes) take a similar approach. These methods share a common flaw that, if no pixels in a source reaches the given threshold, then that source will not be detected even if it is large and clearly visible when taken as a whole. Nevertheless, SExtractor is very commonly used for extended source detection \cite{dalcanton1997number} \cite{longozautomated}.

The 2 Micron All Sky Survey \cite{jarrett20002mass} searched for low surface brightness galaxies (a type of extended source) using a similar thresholding system. Images are first pre-processed to remove all bright sources, and then downsampled and smoothed to improve the signal to noise ratio. A $3\sigma$ threshold is then applied to find peaks which are classed as sources. While fast, this technique is still ultimately limited to evaluating regions individually and achieves approximately a $70-80\%$ success rate on best-case data. It is also limited in that images require significant preprocessing before the algorithm can be run.

A large number of other algorithms for detecting low surface brightness galaxies have been used \cite{kniazev2004low} \cite{walsh2009invisibles} \cite{strauss2002spectroscopic} in the analysis of various sky surveys. The most common pattern with these algorithms is to use SExtractor (or one of its precursors) to find and remove point sources, and then perform extra filtering and post-processing to extract extended sources. While very effective, these algorithms often incorporate a large amount of knowledge specific to their survey, and are designed to detect only specific types of sources. Consequently, they are not useful as general source detection techniques.

\comment{DAOfind \cite{stetson1987daophot} is another popular (though somewhat historic) source detection algorithm, with slightly more involved statistics. It fits a Gaussian profile to each small region of pixels, and calls a region a source if the profile's parameters are close to the expected parameters of a star. This is a very different method of finding sources to SExtractor, as it requires a model of the distribution of a \emph{source}, rather than the distribution of the background. It is also a very restricted method, as the algorithm will only find the sources it knows to look for. DAOfind is particularly capable at performing photometry, but there are indications that SExtractor is still a more effective source detection tool \cite{annunziatella2013inside}. Nevertheless, DAOfind represents a step towards more complex statistical models of the sky.}

Wavelet transforms are another approach to source detection \cite{damiani1997method} \cite{fruscione2006ciao}, and are well-suited to finding extended sources. These transforms, used in a similar fashion to Fourier analysis, are able to extract information about both the shape and position of a source. This sensitivity to shape enables more effective extended source detection than thresholding methods. However, this approach has a preference for sources of a particular shape, is vulnerable to false positives \cite{valtchanov2001comparison}, and is not in widespread use.

Several modern source detection algorithms, most notably BlobCat \cite{hales2012blobcat} and Aegean \cite{aegean}, are based on the idea of `flood-filling' an image. Pixels of high intensity (often $5\sigma$ \cite{aegean}) are used to seed `islands' of source pixels, which are then expanded to nearby pixels. Aegean first applies Laplacian filtering to these islands, before creating curvature maps that are used to characterise the islands as sources. While this is a similar idea to the thresholding performed by SExtractor, the collection of algorithms built on this technique have achieved very good results. In particular, Aegean has been shown to be a highly reliable and effective algorithm, and is quickly gaining traction as a replacement for SExtractor on many radioastronomy tasks.

Source detection approaches based on Bayesian probability theory have been studied increasingly in the last decade. These attempts continue the trend of backing algorithms with rigorous statistical models to extract as much information from data as possible. Bayesian ideas are incorporated to varying degrees, from simple per-pixel model comparisons to sampling from the posterior of a full generative model. Most of these techniques employ Bayesian \emph{statistics}, rather than Bayesian \emph{machine learning}. In fact, there is a notable lack of machine learning tools being used to solve astronomical source detection problems.

Hobson et al. \cite{hobson2003bayesian} model sources as Gaussians and use Markov Chain Monte-Carlo (MCMC) to search for good parameters (position, mean, variance). The number of sources itself is also sampled, and a Poisson prior is used to make the sampler favour fewer sources in general. This forms a very large search space, requiring the algorithm to be run for many iterations. On a $200 \times 200$ pixel image, the authors obtained good results when the posterior is evaluated about 200\,000 times total.

Savage et al. \cite{savage2007bayesian} use Bayesian Information Criterion to find pixels that are more likely to come from a point source distribution than a purely-background distribution. MCMC is used to optimise the parameters of a point source model. While some modifications for extended sources are presented, this method remains primarily applicable to point source detection. This approach also relies on both the sources and the background being Gaussian, and the parameters of the background being known.

A more advanced Bayesian algorithm was proposed by Guglielmetti et. al \cite{guglielmetti2009background} for extended source detection. The algorithm uses a mixture model of two Poisson distributions, one for the background and one for the source, and finds pixels where the source distribution dominates the mixture. To find large sources, the algorithm performs `multiresolution analysis', in which pixels are aggregated into cells and the same procedure is applied. This technique crucially relies on a strong model of both background and source. Unfortunately the method as-presented is applicable only to X-ray telescope data, which is fundamentally different to radio or optical telescope data.

Frean et al. \cite{frean2014source} developed a Bayesian extended source detection with similar underpinnings to ours, based on Anna Friedlander's master's thesis. This used the Dirichlet Compound Multinomial (DCM) distribution as a generative model of sources and the background, which is combined with a binning (discretisation) scheme that captures uncertainty in where bin boundaries should be placed. Sources are modelled as a Gaussian envelope generated by a DCM distribution, and the envelopes are evaluated using a Bayes factor comparison to some model of the background. The algorithm itself does a greedy gradient-based search to find envelopes that are anomalous according to some model of the background. While successful at detecting extended sources, the lack of a full likelihood model means the method has no natural way of finding \emph{all} sources in an image at once. Instead, the algorithm can be run several times, each one with the previously found sources removed.

Source detection algorithms based on Bayesian methods have a common structure: they are composed of an evaluation mechanism and a search mechanism. The evaluation mechanism defines how a region of pixels is decided to be source or background, and is most commonly a direct comparison (such as a Bayes factor or Bayesian Information Criterion) between source and background models. Evaluation mechanisms are well-developed and have been studied extensively, and are the main differentiator between the discussed Bayesian algorithms. The search mechanism defines how regions of to-be-evaluated pixels are selected, and are generally more simple. Most algorithms, particularly point source detection algorithms, search by applying the evaluation function once to every pixel in the image.

Extended source detection algorithms must use a more complex search mechanism, as these sources are rarely visible at the single-pixel level. This alludes to one of the fundamental difficulties of finding extended sources: any algorithm must search for sources at several scales in the image, that is it must perform \emph{aggregation} of some kind. The techniques discussed above take significantly different approaches to this; Wavelet transforms encode scale in the transform itself, Hobson et al. (effectively) perform brute-force search, both Frean et al. and Savage et al. greedily optimise the shape of the Gaussian region, and Guglielmetti et al. combine regions into pixel cells.

\comment{Our algorithm takes a more principled approach to extended source detection than previous work. Oddity is guided entirely by a generative model of the image, so a candidate source is evaluated by comparing the likelihood of a model with that source to the likelihood of a model without. This is desirable, as it allows the algorithm to asymptotically find the \emph{optimal} configuration of sources under its model. Oddity shares a common ancestor with the previous work of Frean et al.\ in that the DCM distribution is used to model source pixels, however that work did not use the model's likelihood as its evaluation mechanism.}

Because of the large search space, robust aggregation is difficult to perform efficiently. If the most intuitive generative model of the sky is used, that is, regions with an arbitrary size and shape are selected to be sources, then aggregation becomes very expensive. Hence, most approaches so far have either been ad-hoc or intractable for large images.

\section{Generative Models} \label{s:generative_models}

A key concept in Bayesian machine learning is a \emph{generative model}. This is a probabilistic description of how observed data was created, and is described by the \emph{likelihood} $P(\text{data} \mid \text{model})$. A model often has some latent (unobserved) variables, such as class labels, for which we wish to infer good values. This is often performed by sampling from the \emph{posterior} $P(\text{model} \mid \text{data})$. The process of inferring the latent variables is known as \emph{inverting} the generative model.

\section{Dirichlet Compound Multinomial}

The Dirichlet Compound Multinomial (DCM) is a discrete, compound probability distribution that will be one of the main building blocks of our algorithm's underlying generative model. The DCM distribution works in two steps. First, a probability vector $\vec p$ is drawn from a \emph{Dirichlet} distribution. Then, some number of observations are drawn from a \emph{multinomial} distribution with probability vector $\vec p$. The DCM is `compound' because it is composed of these two distributions.

The Dirichlet distribution takes a vector of parameters, $\vec \alpha$, which determines the profile of the distributions drawn from it. First, if $\vec\alpha$ has $K$-long vector, then drawn probability vectors will have $K$ elements. The parameter vector can be broken into two components, the \emph{shape}, $\vec s$, and the \emph{concentration}, $C$, where $\vec s$ is a probability vector and $\vec \alpha = C \vec s$. The shape parameter determines the mean distribution drawn from the Dirichlet, and the concentration parameter determines the variance of each component of the vectors. With a very large concentration, draws will be very similar to $\vec s$, and if $\vec \alpha = (1, \ldots, 1)$, then draws are uniformly random.

The Dirichlet distribution can be thought of as drawing from points on the $K$-simplex, which is the collection of all probability vectors length $K$. For example, the 3-simplex can be viewed as the surface of an equilateral triangle in 3-dimensional space, and each point on the triangle is a distribution. The shape parameter determines the mean draw on this plane, and the concentration determines the variance in each dimension. In the context of the DCM distribution, the vector $\vec \alpha$ is called the \emph{hyperparameters}.

The DCM is an example of a generative model, and it has two useful features. First, it allows observations to be modelled as drawn from an \emph{unknown} multinomial distribution. Second, it is also unusual among compound distributions in that it is tractable to calculate the likelihood, $P_\text{DCM}(\vec x \mid \vec \alpha)$. This tractability comes from the fact that the intermediate multinomial does not need to be explicitly calculated. Specifically, the result is \begin{equation}
 \PDCM (\vec x \mid \vec \alpha) = \frac{\Gamma(A)}{\Gamma(N + A)} \prod_{k=1}^K \frac{\Gamma(n_k + \alpha_k)}{\Gamma(\alpha_k)} . \label{e:DCM}
\end{equation}
Where $n_k$ is the number of occurrences of event $k$ in the observations vector $\vec x$, $\Gamma(a)$ is the gamma function, $A = \sum_{k=1}^K \alpha_k$, and $N = \sum_{k=1}^K n_k$. Note that, for integer $a$, $\Gamma(a) = (a-1)!$. We will generally take logs of this equation, yielding \begin{equation}
 \lPDCM (\vec x \mid \vec \alpha) = \log \Gamma(A) - \log \Gamma(N + A) + \sum_{k=1}^K \left[ \log\Gamma(n_k + \alpha_k) - \log \Gamma(\alpha_k) \right] . \label{e:logDCM}
\end{equation}
While the observations $\vec x$ do not appear in the equation directly, they are used to calculate the histogram $n_k$. For convenience this report will consider $\lPDCM(\vec n \mid \vec \alpha)$ as synonymous with $\lPDCM(\vec x \mid \vec \alpha)$ (despite being non-standard notation).

\section{Markov Chains and Gibbs Sampling} \label{s:markov_background}

A Markov chain is a random process that transitions between different states over time. It is initialised to some (often arbitrary) state $\theta^0$, and at each step selects a new state to transition to from a \emph{transition distribution}. The initial state of the Markov chain affects its behaviour in future time steps, but the magnitude of this effect lessens as the chain is run for more steps. Every Markov chain has a \emph{stationary distribution}, which describes its behaviour in the absence of any effect from its initial state. When the behaviour of a Markov chain very closely matches its stationary distribution, that chain is said to have \emph{mixed}. Depending on the complexity of the transition matrix and the quality of the initial state, mixing can take a very long time.

The stationary distribution of a Markov chain can be sampled from by first running the chain until it is mixed, and then drawing samples with a large enough number of iterations between them so as to be i.i.d. This procedure does not require the stationary distribution to ever be explicitly defined, as it arises naturally from the transition distribution and the structure of the chain. This is the key usefulness of Markov chains; very commonly, one needs to sample from a distribution $P$ that is intractable or impossible to sample from exactly. If a Markov chain can be created in such a way that $P$ is its stationary distribution, approximate samples can be drawn from $P$ by running the chain. This procedure is known as Markov Chain Monte Carlo (MCMC).

Gibbs sampling \cite{mackay2003information} is a simple MCMC procedure. Suppose we are sampling from a distribution $P(\theta_1, \ldots, \theta_N)$. Before the first iteration, arbitrarily initialise each variable $\theta_i^0$ (where superscripts represent time). To perform one iteration of Gibbs at time $t+1$, draw new samples for each variable as follows: \begin{equation}
  \theta_i^{t+1}\ \ \sim\ \ P(\theta_i \mid \theta_1^{t+1}, \ldots, \theta_{i-1}^{t+1}, \theta_{i+1}^t, \ldots, \theta_N^t) \label{e:gibbs_bg_update}
\end{equation}
In other words, hold all variables fixed at their current value except the one to be updated, and then draw a new value for the changing variable's state. The distribution in equation \ref{e:gibbs_bg_update} is known as the \emph{full conditional} distribution of $\theta_i^{t+1}$, which is generally known and easy to calculate. Sampling in this fashion creates a Markov chain whose stationary distribution is the posterior. Hence, once the chain has mixed, the variables become a true sample from the posterior. Variables do not need to be updated in any particular or consistent order, as long as every variable is updated every iteration. Gibbs sampling is useful for learning the latent variables of a generative model, so long as the full conditional distributions are known.

\comment{\section{Metropolis Sampling} \label{s:metropolis_background}

The Metropolis-Hastings algorithm is a second sampling algorithm for approximating samples from a complex posterior. Metropolis also works iteratively, on a system of proposal transitions between states that are either accepted or rejected. Suppose $Q(\theta^*\mid\theta^t)$ is a \emph{transition distribution}, which can be sampled to offer a proposed transition, $\theta^*$, for the next iteration, which might be dependent on the previous state $\theta^t$. To run the algorithm, first initialise $\theta^0$ arbitrarily to some state with non-zero probability in the posterior. Then, at time $t+1$, sample a candidate proposal $\theta^* \sim Q$. Next, calculate the \emph{acceptance ratio} as follows \begin{equation}
 r = \frac{P(\theta^*) Q(\theta^t | \theta^*)}{P(\theta^t) Q(\theta^* | \theta^t)}. \label{e:acceptance_ratio}
\end{equation}
Finally, accept the proposal with probability $min(1,r)$. If the proposal is accepted, $\theta^{t+1} = \theta^*$, otherwise $\theta^{t+1} = \theta^t$. Much like with Gibbs sampling, as time tends to infinity the state tends to a true sample from the posterior $P$.

Gibbs sampling is a special case of Metropolis-Hastings, in which only a single parameter of the model is varied on any iteration. Gibbs is conceptually simpler, and is generally used when the parameters take on a small number of discrete values. Depending on the distribution being sampled from, changing parameters individually often avoids the need to evaluate the full posterior of $P$ which makes it a cheaper algorithm to run.}
